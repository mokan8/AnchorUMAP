{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itbUwASCZ1lj"
   },
   "source": [
    "# Triangular adaptation of UMAP\n",
    "\n",
    "This is a project to adapt the UMAP algorithm to incoroporate 2-simplices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6ntJIvWZ-Yk"
   },
   "source": [
    "##  Installing necessary packages\n",
    "\n",
    "Initially I had some dependency issues, and these package installations resolves them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WGlzmx55eoE",
    "outputId": "e0475422-773e-476a-fa97-84a17eaf1b4a"
   },
   "outputs": [],
   "source": [
    "#need umap package, but there are weird dependency issues and this is the fix for collab\n",
    "!pip uninstall -y torch torchvision sympy\n",
    "!pip uninstall -y scipy\n",
    "!pip install scipy\n",
    "!pip install ipywidgets plotly scikit-learn\n",
    "!pip install scanpy python-igraph louvain umap-learn matplotlib pandas\n",
    "!pip install ripser persim\n",
    "!pip install flagser persim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeSbkbbo_MFj"
   },
   "source": [
    "# Neccesary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgxUfp0LSz7n"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import umap\n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.patches import Polygon\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_swiss_roll, make_s_curve, make_circles\n",
    "from ipywidgets import (\n",
    "    FloatSlider, IntSlider, Checkbox, Dropdown,\n",
    "    VBox, HBox, Label, Button, Layout, interactive_output, HTML\n",
    ")\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Image\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "import datetime\n",
    "import scipy.sparse as sp\n",
    "from sklearn.manifold import trustworthiness\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams, wasserstein, bottleneck\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from umap.umap_ import simplicial_set_embedding\n",
    "from umap.umap_ import compute_membership_strengths\n",
    "from umap.umap_ import smooth_knn_dist\n",
    "from scipy.spatial import distance_matrix\n",
    "from pynndescent import NNDescent\n",
    "from umap.utils import (\n",
    "    submatrix,\n",
    "    ts,\n",
    "    csr_unique,\n",
    "    fast_knn_indices\n",
    ")\n",
    "import flagser\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from google.colab import output\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from collections import defaultdict\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9wAhnX4a1Hh"
   },
   "source": [
    "## Nearest neighbors\n",
    "UMAP uses a k-nn graph to find pairwise relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgvNCL9VjloP"
   },
   "outputs": [],
   "source": [
    "#nearest neighbor function from umap\n",
    "def nearest_neighbors(\n",
    "    X,\n",
    "    n_neighbors,\n",
    "    metric,\n",
    "    metric_kwds,\n",
    "    angular,\n",
    "    random_state,\n",
    "    low_memory=True,\n",
    "    use_pynndescent=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"Compute the ``n_neighbors`` nearest points for each data point in ``X``\n",
    "    under ``metric``. This may be exact, but more likely is approximated via\n",
    "    nearest neighbor descent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array of shape (n_samples, n_features)\n",
    "        The input data to compute the k-neighbor graph of.\n",
    "\n",
    "    n_neighbors: int\n",
    "        The number of nearest neighbors to compute for each sample in ``X``.\n",
    "\n",
    "    metric: string or callable\n",
    "        The metric to use for the computation.\n",
    "\n",
    "    metric_kwds: dict\n",
    "        Any arguments to pass to the metric computation function.\n",
    "\n",
    "    angular: bool\n",
    "        Whether to use angular rp trees in NN approximation.\n",
    "\n",
    "    random_state: np.random state\n",
    "        The random state to use for approximate NN computations.\n",
    "\n",
    "    low_memory: bool (optional, default True)\n",
    "        Whether to pursue lower memory NNdescent.\n",
    "\n",
    "    verbose: bool (optional, default False)\n",
    "        Whether to print status data during the computation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    knn_indices: array of shape (n_samples, n_neighbors)\n",
    "        The indices on the ``n_neighbors`` closest points in the dataset.\n",
    "\n",
    "    knn_dists: array of shape (n_samples, n_neighbors)\n",
    "        The distances to the ``n_neighbors`` closest points in the dataset.\n",
    "\n",
    "    rp_forest: list of trees\n",
    "        The random projection forest used for searching (if used, None otherwise).\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(ts(), \"Finding Nearest Neighbors\")\n",
    "\n",
    "    if metric == \"precomputed\":\n",
    "        # Note that this does not support sparse distance matrices yet ...\n",
    "        # Compute indices of n nearest neighbors\n",
    "        knn_indices = fast_knn_indices(X, n_neighbors)\n",
    "        # knn_indices = np.argsort(X)[:, :n_neighbors]\n",
    "        # Compute the nearest neighbor distances\n",
    "        #   (equivalent to np.sort(X)[:,:n_neighbors])\n",
    "        knn_dists = X[np.arange(X.shape[0])[:, None], knn_indices].copy()\n",
    "        # Prune any nearest neighbours that are infinite distance apart.\n",
    "        disconnected_index = knn_dists == np.inf\n",
    "        knn_indices[disconnected_index] = -1\n",
    "\n",
    "        knn_search_index = None\n",
    "    else:\n",
    "        # TODO: Hacked values for now\n",
    "        n_trees = min(64, 5 + int(round((X.shape[0]) ** 0.5 / 20.0)))\n",
    "        n_iters = max(5, int(round(np.log2(X.shape[0]))))\n",
    "\n",
    "        knn_search_index = NNDescent(\n",
    "            X,\n",
    "            n_neighbors=n_neighbors,\n",
    "            metric=metric,\n",
    "            metric_kwds=metric_kwds,\n",
    "            random_state=random_state,\n",
    "            n_trees=n_trees,\n",
    "            n_iters=n_iters,\n",
    "            max_candidates=60,\n",
    "            low_memory=low_memory,\n",
    "            n_jobs=n_jobs,\n",
    "            verbose=verbose,\n",
    "            compressed=False,\n",
    "        )\n",
    "        knn_indices, knn_dists = knn_search_index.neighbor_graph\n",
    "\n",
    "    if verbose:\n",
    "        print(ts(), \"Finished Nearest Neighbor Search\")\n",
    "    return knn_indices, knn_dists, knn_search_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkxDXxBGaCZt"
   },
   "source": [
    "# Test data sets\n",
    "\n",
    "Here we define some geometrically simple test data, to see how our algorithm works.  We begin by creating a 2D grids of points.\n",
    "\n",
    "Put all sample data sets up here.  Give them nice names, like X_grid, X_circle, X_torus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPDj0iZQ2mpZ"
   },
   "source": [
    "We begin by creating 1d coordinate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pz4DJEHNTJTK"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 5)  # 5 evenly spaced points from 0 to 1\n",
    "y = np.linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LptaDq8n2s5z"
   },
   "source": [
    "Combine these two 1-d arrays into a 2-d grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dx0zrjX2TWFF"
   },
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjUyPgS123yM"
   },
   "source": [
    "We now have an evenly spaced grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzhYBmZTUdES",
    "outputId": "d4dac75a-8c18-4138-8782-d4f61da60a1f"
   },
   "outputs": [],
   "source": [
    "points = np.column_stack([X.ravel(), Y.ravel()])\n",
    "#rename points to match UMAP notation of X\n",
    "X_grid = points\n",
    "print(X_grid.shape)   # (25, 2)\n",
    "print(X_grid[:10])     # first few (x, y) points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkt8vpg43fl6"
   },
   "source": [
    "Need to update the index information for the grid dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNP8tMk9qUAZ",
    "outputId": "579d9d4e-7eab-4304-d81e-96fa212cc261"
   },
   "outputs": [],
   "source": [
    "knn_indices_grid, knn_dists_grid, knn_search_index_grid = nearest_neighbors(X_grid,10,metric='euclidean',metric_kwds={},angular=False,random_state=42)\n",
    "print (knn_indices_grid[:3], knn_dists_grid[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3k0piVEx9Yu"
   },
   "source": [
    "# Noisy Circle\n",
    "\n",
    "Now we check a new test dataset, that of a noisy circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpLukA2sZ6vE"
   },
   "outputs": [],
   "source": [
    "def generate_noisy_circle(n_points=100, radius=1.0, noise_std=0.05, random_seed=42):\n",
    "    \"\"\"\n",
    "    Generate points roughly on a circle with Gaussian noise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_points : int\n",
    "        Number of points to generate.\n",
    "    radius : float\n",
    "        Radius of the circle.\n",
    "    noise_std : float\n",
    "        Standard deviation of Gaussian noise added to each coordinate.\n",
    "    random_seed : int\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : (n_points, 2) array\n",
    "        Coordinates of noisy points on the circle.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Generate angles evenly spaced around the circle\n",
    "    angles = np.linspace(0, 2 * np.pi, n_points, endpoint=False)\n",
    "\n",
    "    # Circle coordinates\n",
    "    x = radius * np.cos(angles)\n",
    "    y = radius * np.sin(angles)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    x += np.random.normal(scale=noise_std, size=n_points)\n",
    "    y += np.random.normal(scale=noise_std, size=n_points)\n",
    "\n",
    "    X = np.column_stack([x, y])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU5bv9zJ6JFH"
   },
   "source": [
    "We now generate the circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nc7Nm_qrbEDe"
   },
   "outputs": [],
   "source": [
    "X_circle = generate_noisy_circle(n_points=100, radius=1.0, noise_std=0.05, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV51sj5CxkIm"
   },
   "source": [
    "This is what the points look like for the 2d noisy circle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQvrXTc4bLNy",
    "outputId": "fb25329b-2efb-455c-ccd9-99d57a43bce6"
   },
   "outputs": [],
   "source": [
    "print (X_circle[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH7MyV5O0unI"
   },
   "source": [
    "Indices must be updated for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REtJsTEzetkP"
   },
   "outputs": [],
   "source": [
    "knn_indices_circle, knn_dists_circle, knn_search_index_circle = nearest_neighbors(X_circle,10,metric='euclidean',metric_kwds={},angular=False,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cBTWe83yue2"
   },
   "source": [
    "# Noisy Torus\n",
    "We are now going to inspect a third test data set, that of a noisy torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KbhucRdZdMGO"
   },
   "outputs": [],
   "source": [
    "def generate_noisy_torus(n_points=500, R=2.0, r=0.5, noise_std=0.05, random_seed=42):\n",
    "    \"\"\"\n",
    "    Generate points roughly on a torus with Gaussian noise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_points : int\n",
    "        Total number of points to generate.\n",
    "    R : float\n",
    "        Major radius (distance from center of tube to center of torus).\n",
    "    r : float\n",
    "        Minor radius (radius of the tube).\n",
    "    noise_std : float\n",
    "        Standard deviation of Gaussian noise added to each coordinate.\n",
    "    random_seed : int\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : (n_points, 3) array\n",
    "        Coordinates of noisy points on the torus.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Random angles for torus param\n",
    "    theta = np.random.uniform(0, 2*np.pi, n_points)  # around major circle\n",
    "    phi = np.random.uniform(0, 2*np.pi, n_points)    # around minor circle\n",
    "\n",
    "    # Parametric equations\n",
    "    x = (R + r * np.cos(phi)) * np.cos(theta)\n",
    "    y = (R + r * np.cos(phi)) * np.sin(theta)\n",
    "    z = r * np.sin(phi)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    x += np.random.normal(scale=noise_std, size=n_points)\n",
    "    y += np.random.normal(scale=noise_std, size=n_points)\n",
    "    z += np.random.normal(scale=noise_std, size=n_points)\n",
    "\n",
    "    X = np.column_stack([x, y, z])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cZmuz-m1SzI"
   },
   "source": [
    "Next we generate the torus itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZralordWlB"
   },
   "outputs": [],
   "source": [
    "X_torus = generate_noisy_torus(n_points=500, R=2.0, r=0.5, noise_std=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raV-xFBv1Qax"
   },
   "source": [
    "Indices must be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcPGU9O4fOgs"
   },
   "outputs": [],
   "source": [
    "knn_indices_torus, knn_dists_torus, knn_search_index_torus = nearest_neighbors(X_torus,10,metric='euclidean',metric_kwds={},angular=False,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH-DBYQ91IYn"
   },
   "source": [
    "Below we can inspect the coordinates of points of the torus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68oW57DRdabL",
    "outputId": "b64306fc-e255-44dd-de3b-fe435dc6efad"
   },
   "outputs": [],
   "source": [
    "print(X_torus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKbsl8CEa5tF"
   },
   "source": [
    "## Finding triangles\n",
    "\n",
    "> This section outlines the triangle finding procedure\n",
    "\n",
    "We will use the knn data to find which nodes lie within each other's neighborhoods. For example, if a is b's neighbor, but b is not a's neighbor, then there will be no triangle found. However if three nodes appear in eachothers nearest neighbors, then we have a candidate triangle.\n",
    "\n",
    "Regardless, we precompute the distance matrix for each node, and with that we find the standard deviation of each distance matrix. We use this statistical info to find edges that are unusually close together. We also normalize the weight of each edge using the standard deviation. Ultimately we get three new edges if we find a triangle, and the edge ab will eventually connect the anchor node in the center of the traingle to node c.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThQ56EfOur8m"
   },
   "source": [
    "Edge weights in UMAP are always between 0 and 1 so this function makes sure our weights are approptiate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkWGyr8ExTi_"
   },
   "outputs": [],
   "source": [
    "def weight_fn(d, scale=5.0):\n",
    "    return 1 / (1 + np.exp(scale * d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGArWdllNEoF"
   },
   "outputs": [],
   "source": [
    "def find_triangles_from_local(X, knn_indices, min_edge = 0.5, tension = 3):\n",
    "        \"\"\"\n",
    "        Given data X and a knn_indices array, find triangles (a,b,c).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (n_samples, n_features) array\n",
    "            Original data.\n",
    "        knn_indices : (n_samples, k) array\n",
    "            k-nearest neighbors for each sample.\n",
    "        Returns\n",
    "        -------\n",
    "        triangles : list of tuples\n",
    "            Each tuple is (a, b, c, w_bc, w_ac, w_ab)\n",
    "            where w_* are the weighted edge strengths obtained from z-score distances.\n",
    "        \"\"\"\n",
    "        n_samples, k = knn_indices.shape\n",
    "        triangles = []\n",
    "        seen = set()  # track unique (a,b,c)\n",
    "        local_means = np.zeros(n_samples)\n",
    "        local_stds = np.zeros(n_samples)\n",
    "        for p in range(n_samples):\n",
    "          neighbors = knn_indices[p]\n",
    "          neighbor_coords = X[neighbors]\n",
    "          DM = distance_matrix(neighbor_coords, neighbor_coords)\n",
    "          local_means[p] = np.mean(DM)\n",
    "          local_stds[p] = np.std(DM)\n",
    "\n",
    "        for a in range(n_samples):\n",
    "            neighbors = knn_indices[a]\n",
    "            neighbor_coords = X[neighbors]\n",
    "\n",
    "            # Now check all neighbor pairs (b, c)\n",
    "            for i in range(k):\n",
    "                for j in range(i + 1, k):\n",
    "                    b = neighbors[i]\n",
    "                    c = neighbors[j]\n",
    "                    b_neighbors = knn_indices[b]\n",
    "                    c_neighbors = knn_indices[c]\n",
    "                    if (a in b_neighbors) and (c in b_neighbors) and (b in c_neighbors) and (a in c_neighbors):\n",
    "                    # distance between b and c in neighbor space\n",
    "                      d_bc = np.linalg.norm(X[c] - X[b])\n",
    "                      d_ab = np.linalg.norm(X[b] - X[a])\n",
    "                      d_ac = np.linalg.norm(X[c] - X[a])\n",
    "\n",
    "                      # Normalize by mean_val too\n",
    "                      d_ab = (d_ab - local_means[c]) / local_stds[c] #z-score\n",
    "                      d_ac = (d_ac - local_means[b]) / local_stds[b] #z-score\n",
    "                      d_bc = (d_bc - local_means[a]) / local_stds[a] #z-score\n",
    "\n",
    "                      # Store triangle, edges already weighted\n",
    "                      if a < b < c:\n",
    "                        key = tuple(sorted((a, b, c)))\n",
    "                        if key not in seen:\n",
    "                            seen.add(key)\n",
    "                            w_bc = weight_fn(d_bc)\n",
    "                            w_ac = weight_fn(d_ac)\n",
    "                            w_ab = weight_fn(d_ab)\n",
    "                            #remove low quality triangles\n",
    "                            if min(w_ab, w_ac, w_bc) >= min_edge:\n",
    "                              triangles.append((a, b, c, tension*w_bc, tension*w_ac, tension*w_ab))\n",
    "        return triangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28WODvsmvlXh"
   },
   "source": [
    "After running the find_triangles_from_local we have a list of triangles found from the data. Here we inspect them to see what kind of data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgvf-lcgt-yV",
    "outputId": "a86fad7a-1330-4d1c-8c81-d837f9fe85b0"
   },
   "outputs": [],
   "source": [
    "triangles = find_triangles_from_local(X_grid,knn_indices_grid)\n",
    "i = 0\n",
    "for tri in triangles:\n",
    "  if i == 3:\n",
    "    continue\n",
    "  a, b, c, w_bc, w_ac, w_ab = tri\n",
    "  print(f\"Triangle: ({a}, {b}, {c}) | w_bc={w_bc:.3f}, w_ac={w_ac:.3f}, w_ab={w_ab:.3f}\")\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x47dNyozkBEY",
    "outputId": "b9ce569e-9be5-4310-c354-14f0f979ac6e"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for tri in triangles:\n",
    "  if i == 3:\n",
    "    continue\n",
    "  a, b, c, w_bc, w_ac, w_ab = tri\n",
    "  print ({a},{b},{c})\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2tNz_FI0zRL"
   },
   "source": [
    "Here we find the triangles in the circle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u985BbKCbvz8",
    "outputId": "bd0cbfe2-29cd-4fb4-b7d9-30b2a352897c"
   },
   "outputs": [],
   "source": [
    "circle_tri = find_triangles_from_local(X_circle,knn_indices_circle)\n",
    "i = 0\n",
    "for tri in circle_tri:\n",
    "    if i == 3:\n",
    "      continue\n",
    "    a, b, c, w_bc, w_ac, w_ab = tri\n",
    "    print(f\"Triangle: ({a}, {b}, {c}) | w_bc={w_bc:.3f}, w_ac={w_ac:.3f}, w_ab={w_ab:.3f}\")\n",
    "    print(f\"Coords: a = ({X_circle[a][0]:.3f}, {X_circle[a][1]:.3f},), b = ({X_circle[b][0]:.3f}, {X_circle[b][1]:.3f}), c = ({X_circle[c][0]:.3f}, {X_circle[c][1]:.3f})\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5h3v1_sB4r4I"
   },
   "source": [
    "Here we find triangles in the torus data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWYcpCyhdnD0",
    "outputId": "234aadc5-1309-4436-fa47-f60302120502"
   },
   "outputs": [],
   "source": [
    "tor_tri = find_triangles_from_local(X_torus,knn_indices_torus)\n",
    "i = 0\n",
    "for tri in tor_tri:\n",
    "    if i == 3:\n",
    "      continue\n",
    "    a, b, c, w_bc, w_ac, w_ab = tri\n",
    "    print(f\"Triangle: ({a}, {b}, {c}) | w_bc={w_bc:.3f}, w_ac={w_ac:.3f}, w_ab={w_ab:.3f}\")\n",
    "    print(f\"Coords: a = ({X_torus[a][0]:.3f}, {X_torus[a][1]:.3f}, {X_torus[a][2]:.3f}), \"\n",
    "      f\"b = ({X_torus[b][0]:.3f}, {X_torus[b][1]:.3f}, {X_torus[b][2]:.3f}), \"\n",
    "      f\"c = ({X_torus[c][0]:.3f}, {X_torus[c][1]:.3f}, {X_torus[c][2]:.3f})\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpBcSln2bm3G"
   },
   "source": [
    "## Pictures of triangles.\n",
    "\n",
    "Draw the mesh of triangles, filled at 0.1 or 0.2 opacity, on the raw data in Euclidean space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "vSPp-1YIzmx3",
    "outputId": "c04bf6bd-4ff9-4ac3-9ba5-744fa7677c96"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(X_grid[:,0], X_grid[:,1], s=10, color='black', alpha=0.9)\n",
    "\n",
    "for (a,b,c,_,_,_) in triangles:\n",
    "    pts = X_grid[[a,b,c]]\n",
    "    ax.fill(pts[:,0], pts[:,1], color='tab:blue', alpha=0.1) #, edgecolor='none')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU2cKX14qCoi"
   },
   "source": [
    "# Why is there asymmetry?\n",
    "Asymmetry arises from the nearest neighbors algorithm from UMAP. We can see the triangles evolve as we change the number of neighbors. When we have a regular grid there may be many points that are an equal distance away, therefore the nearest neighbors algorithm has to choose what point to add to the list when there is only one option left but many candidate points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "3bc17c36",
    "outputId": "b4ff0064-18aa-41b4-d454-3e4ced5b8c09"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(X_circle[:,0], X_circle[:,1], s=10, color='black', alpha=0.6)\n",
    "\n",
    "for (a,b,c,_,_,_) in circle_tri:\n",
    "    pts = X_circle[[a,b,c]]\n",
    "    ax.fill(pts[:,0], pts[:,1], color='tab:blue', alpha=0.2, edgecolor='none')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Noisy Circle with Triangles')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "03bb5ce9",
    "outputId": "e32dc194-3e87-4483-f746-6abfd7a4e62d"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot of the torus data\n",
    "ax.scatter(X_torus[:, 0], X_torus[:, 1], X_torus[:, 2], s=10, color='black', alpha=0.6)\n",
    "\n",
    "# Draw the triangles\n",
    "for (a, b, c, _, _, _) in tor_tri:\n",
    "    pts = X_torus[[a, b, c]]\n",
    "    # Create a polygon for the triangle\n",
    "    triangle_polygon = Poly3DCollection([pts], alpha=0.2, facecolor='tab:blue', edgecolor='none')\n",
    "    ax.add_collection3d(triangle_polygon)\n",
    "\n",
    "ax.set_title('Torus with Triangles')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OoS5k2rwZj0"
   },
   "source": [
    "# Regular datasets\n",
    "Noise makes datasets mare natural, but let's see what happens with completely regular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urfVMYkExFKW"
   },
   "outputs": [],
   "source": [
    "def generate_circle_points(n_points=100, radius=1.0, random_seed=42):\n",
    "    \"\"\"\n",
    "    Generate evenly spaced points on a circle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_points : int\n",
    "        Number of points to generate.\n",
    "    radius : float\n",
    "        Radius of the circle.\n",
    "    random_seed : int\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : (n_points, 2) array\n",
    "        Coordinates of evenly spaced points on the circle.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Generate evenly spaced angles around the circle\n",
    "    angles = np.linspace(0, 2 * np.pi, n_points, endpoint=False)\n",
    "\n",
    "    # Compute coordinates on the circle\n",
    "    x = radius * np.cos(angles)\n",
    "    y = radius * np.sin(angles)\n",
    "\n",
    "    X = np.column_stack([x, y])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9d0LYW7xZPh"
   },
   "outputs": [],
   "source": [
    "reg_circle = generate_circle_points(n_points=100, radius=1.0, random_seed=42)\n",
    "reg_circle_knn_indices, reg_circle_knn_dists, reg_circle_knn_search_index = nearest_neighbors(reg_circle,9,metric='euclidean',metric_kwds={},angular=False,random_state=42)\n",
    "reg_circle_tri = find_triangles_from_local(reg_circle,reg_circle_knn_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "IyRUpnumy87W",
    "outputId": "4613e801-87aa-4310-fc92-9c1a88c15e57"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(reg_circle[:,0], reg_circle[:,1], s=10, color='black', alpha=0.6)\n",
    "\n",
    "for (a, b, c, *_) in circle_tri:\n",
    "    pts = reg_circle[[a, b, c]]\n",
    "    ax.fill(pts[:,0], pts[:,1], color='tab:blue', alpha=0.2, edgecolor='none')\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Regular Circle with Triangles')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BVFt1arx7Ix"
   },
   "source": [
    "Use Torus from eariler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rV8Y7Q902LQJ"
   },
   "outputs": [],
   "source": [
    "def generate_torus_points(n_major=30, n_minor=30, R=2.0, r=0.7, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    theta = np.linspace(0, 2 * np.pi, n_major, endpoint=False)\n",
    "    phi = np.linspace(0, 2 * np.pi, n_minor, endpoint=False)\n",
    "    theta, phi = np.meshgrid(theta, phi)\n",
    "    x = (R + r * np.cos(phi)) * np.cos(theta)\n",
    "    y = (R + r * np.cos(phi)) * np.sin(theta)\n",
    "    z = r * np.sin(phi)\n",
    "    X = np.column_stack([x.ravel(), y.ravel(), z.ravel()])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oMD30PA3kiD"
   },
   "outputs": [],
   "source": [
    "# Generate torus points\n",
    "reg_torus = generate_torus_points(n_major=30, n_minor=30, R=2.0, r=0.7)\n",
    "\n",
    "# Compute neighbors & triangles\n",
    "reg_torus_knn_indices, reg_torus_knn_dists, reg_torus_knn_search_index = nearest_neighbors(\n",
    "    reg_torus, 9, metric='euclidean', metric_kwds={}, angular=False, random_state=42\n",
    ")\n",
    "reg_torus_tri = find_triangles_from_local(reg_torus, reg_torus_knn_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0q90sEg2x_3H"
   },
   "source": [
    "Here we verify we found some triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "So_jssEc4IW1",
    "outputId": "f970448a-be32-4b5b-8d23-0b2d3f6dbbf6"
   },
   "outputs": [],
   "source": [
    "print(len(reg_torus_tri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HwuHbLdyFoo"
   },
   "source": [
    "Now we can see them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "zXk4o0Fh4B7r",
    "outputId": "412028b6-41a6-4445-d97f-02d87bac2111"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot of the torus points\n",
    "ax.scatter(reg_torus[:,0], reg_torus[:,1], reg_torus[:,2], s=10, color='black', alpha=0.6)\n",
    "\n",
    "# Draw the triangles using Poly3DCollection, light blue and semi-transparent\n",
    "for (a, b, c, *_) in reg_torus_tri:\n",
    "    pts = reg_torus[[a, b, c]]\n",
    "    triangle_polygon = Poly3DCollection(\n",
    "        [pts],\n",
    "        alpha=0.2,\n",
    "        facecolor='tab:blue',\n",
    "        edgecolor='none'\n",
    "    )\n",
    "    ax.add_collection3d(triangle_polygon)\n",
    "\n",
    "ax.set_title('Regular Torus with Triangles')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_box_aspect([1,1,1])  # Equal aspect ratio\n",
    "ax.view_init(elev=25, azim=35)  # Nice viewing angle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hESgPEeYbybK"
   },
   "source": [
    "# Start of UMAP pipeline with triangles\n",
    "\n",
    "We will now compute the UMAP graph incorporating the triangles found. First we have the function that creates the anchor edges from the center node to the original triangle nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PS4SblFH7voh"
   },
   "outputs": [],
   "source": [
    "def build_anchor_edges(triangles, n_samples):\n",
    "        \"\"\"Build edges connecting anchors to their triangle vertices.\"\"\"\n",
    "        edges = []\n",
    "        for t_id, (a, b, c, w_bc, w_ac, w_ab) in enumerate(triangles):\n",
    "            anchor_idx = n_samples + t_id\n",
    "\n",
    "            # anchor to a (weight comes from edge bc)\n",
    "            edges.append((anchor_idx, a, w_bc))\n",
    "            edges.append((a, anchor_idx, w_bc))\n",
    "\n",
    "            # anchor to b (weight comes from edge ac)\n",
    "            edges.append((anchor_idx, b, w_ac))\n",
    "            edges.append((b, anchor_idx, w_ac))\n",
    "\n",
    "            # anchor to c (weight comes from edge ab)\n",
    "            edges.append((anchor_idx, c, w_ab))\n",
    "            edges.append((c, anchor_idx, w_ab))\n",
    "\n",
    "        return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OneSVZVrDhvl"
   },
   "source": [
    "This function creates the anchors that go in the center of each triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfz3zrHX7xA3"
   },
   "outputs": [],
   "source": [
    "def make_anchors(triangles, X):\n",
    "        \"\"\"Create anchor points at triangle centroids.\"\"\"\n",
    "        if not triangles:\n",
    "            return np.empty((0, X.shape[1]))\n",
    "\n",
    "        anchor_coords = []\n",
    "        for (a, b, c, w_ab, w_ac, w_bc) in triangles:\n",
    "            total_w = w_ab + w_ac + w_bc + 1e-9\n",
    "            centroid = (w_bc * X[a] + w_ac * X[b] + w_ab * X[c]) / total_w\n",
    "            anchor_coords.append(centroid)\n",
    "        return np.array(anchor_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA7fGR2UDlTO"
   },
   "source": [
    "This function creats a new graph that incorporates our triangles into the UMAP graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kckogwR97MTD"
   },
   "outputs": [],
   "source": [
    "def _build_augmented_graph(X, knn_indices, knn_dists, sigmas, rhos, return_dists=None):\n",
    "        \"\"\"Build the fuzzy simplicial set including anchor points.\"\"\"\n",
    "        # Compute standard membership strengths\n",
    "        rows, cols, vals, dists = compute_membership_strengths(\n",
    "            knn_indices, knn_dists, sigmas, rhos, return_dists\n",
    "        )\n",
    "\n",
    "        # Find triangles and create anchors\n",
    "        triangles = find_triangles_from_local(X, knn_indices)\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        if len(triangles) > 0:\n",
    "            # Create anchor points\n",
    "            anchors = make_anchors(triangles, X)\n",
    "            n_anchors_ = anchors.shape[0]\n",
    "\n",
    "            # Augment data with anchors\n",
    "            X_aug = np.vstack([X, anchors])\n",
    "\n",
    "            # Build anchor edges\n",
    "            anchor_edges = build_anchor_edges(triangles, n_samples)\n",
    "\n",
    "            # Add anchor edges to graph\n",
    "            if anchor_edges:\n",
    "                anchor_rows, anchor_cols, anchor_vals = zip(*anchor_edges)\n",
    "                rows = np.concatenate([rows, np.array(anchor_rows, dtype=np.int32)])\n",
    "                cols = np.concatenate([cols, np.array(anchor_cols, dtype=np.int32)])\n",
    "                vals = np.concatenate([vals, np.array(anchor_vals, dtype=np.float32)])\n",
    "\n",
    "            # Update graph size to include anchors\n",
    "            graph_size = n_samples + n_anchors_\n",
    "        else:\n",
    "            X_aug = X\n",
    "            graph_size = n_samples\n",
    "            n_anchors_ = 0\n",
    "\n",
    "        # Create sparse matrix with correct size\n",
    "        graph = sp.coo_matrix(\n",
    "            (vals, (rows, cols)),\n",
    "            shape=(graph_size, graph_size)\n",
    "        )\n",
    "        graph.eliminate_zeros()\n",
    "\n",
    "        return graph, X_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWJS2K0tDyVA"
   },
   "source": [
    "We will now build a 3-d grid and construct a UMAP embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3dtPIHT8IQ4"
   },
   "outputs": [],
   "source": [
    "# 1D coordinate arrays\n",
    "x = np.linspace(0, 1, 5)  # 5 evenly spaced points from 0 to 1\n",
    "y = np.linspace(0, 1, 5)\n",
    "z = np.linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E76EBxf9-lc8"
   },
   "outputs": [],
   "source": [
    "# Create a 3D grid\n",
    "X, Y, Z = np.meshgrid(x, y, z)\n",
    "points = np.column_stack([X.ravel(), Y.ravel(), Z.ravel()])\n",
    "X = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC8BbGCz-tMo",
    "outputId": "72d3e6cb-79f5-4450-f7c3-ed9cfa4b9b73"
   },
   "outputs": [],
   "source": [
    "#find triangles, if len(triangles) > 0, then some were found\n",
    "knn_indices, knn_dists, knn_search_index = nearest_neighbors(X,10,metric='euclidean',metric_kwds={},angular=False,random_state=42)\n",
    "triangles = find_triangles_from_local(X,knn_indices)\n",
    "print(len(triangles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doTyTVrJ0Iq3"
   },
   "source": [
    "We need local paramters, sigma and rho. Sigma is a scaling parameter for local geomtery, and rho is the distance to the nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYhj1Q_u-jWu"
   },
   "outputs": [],
   "source": [
    "sigmas, rhos = smooth_knn_dist(knn_dists, float(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxJ_2Q380UwL"
   },
   "source": [
    "Building the augmented graph requires our data and local parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjDAunG_7NwZ"
   },
   "outputs": [],
   "source": [
    "# Build augmented graph\n",
    "graph, X_aug = _build_augmented_graph(\n",
    "      X, knn_indices, knn_dists, sigmas, rhos\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNCx1lP70f_1"
   },
   "source": [
    "We store the UMAP graph as a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICTvDoOi-4LL",
    "outputId": "273f3b6f-5a3a-442c-c6b5-f9babcc48ee3"
   },
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mD6CXPHE_EAf",
    "outputId": "01246878-b527-4909-c059-942dbf6ccb87"
   },
   "outputs": [],
   "source": [
    "X_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtscKxM4b50o"
   },
   "source": [
    "The following operatins are preformed in the creation of the fuzzy simplicial set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0Hbx0tD_GMY"
   },
   "outputs": [],
   "source": [
    "# Apply set operations\n",
    "transpose = graph.transpose()\n",
    "prod_matrix = graph.multiply(transpose)\n",
    "\n",
    "# Define set_op_mix_ratio, 1 is default for umap\n",
    "set_op_mix_ratio = 1.0\n",
    "\n",
    "graph = (set_op_mix_ratio * (graph + transpose - prod_matrix)\n",
    "            + (1.0 - set_op_mix_ratio) * prod_matrix\n",
    "        )\n",
    "graph.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEaXTclZz-h6"
   },
   "source": [
    "We now have a UMAP graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92-Y1WtE_b4m",
    "outputId": "5ab3591a-4c4d-4fa9-aeeb-759bd0e59289"
   },
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "889JFNV0bgF7"
   },
   "source": [
    "a and b are UMAP parameters, here we assign both to their defualt values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Scy4I3RaAjO7"
   },
   "outputs": [],
   "source": [
    "spread, min_dist = 1, 0.1\n",
    "a, b = umap.umap_.find_ab_params(spread, min_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uK_TjprTbpNq"
   },
   "source": [
    "We are now ready to compute the embedding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otfw2dCIBA8l"
   },
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(42)\n",
    "\n",
    "embedding = simplicial_set_embedding(\n",
    "    X_aug,\n",
    "    graph,\n",
    "    n_components=2,\n",
    "    initial_alpha=1.0,        # replaces learning_rate\n",
    "    a=a,\n",
    "    b=b,\n",
    "    gamma=1,                  # replaces repulsion_strength\n",
    "    negative_sample_rate=5,\n",
    "    n_epochs=200,\n",
    "    init='spectral',\n",
    "    random_state=rs,\n",
    "    metric='euclidean',\n",
    "    metric_kwds={},\n",
    "    densmap=False,\n",
    "    densmap_kwds={},           # reintroduced for backward compatibility\n",
    "    output_dens=False,\n",
    "    verbose=False,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tta3TX3O0DHE"
   },
   "source": [
    "This is the geometric embedding into 2-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EQQqu3wCZmS",
    "outputId": "76bfa019-47b4-4aa7-d394-f6ffb2c631f0"
   },
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUORqMMeBpVy"
   },
   "source": [
    "# The data is now plottable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "9pBQtrhaBmhO",
    "outputId": "7546c0e1-9e3e-4407-d0ad-2b934b6e40da"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], s=10, c='black', alpha=0.7)\n",
    "plt.title(\"2D UMAP Embedding\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sb_-pxmgsnQz"
   },
   "source": [
    "# AnchorUMAP\n",
    "\n",
    "Below we have the full anchorUMAP class so that we can easily compare anchor umap versus regular umap in some test cases. Could also uplopad it and import it but that seems harder to run on multiple machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6O7wjd_LsmXH"
   },
   "outputs": [],
   "source": [
    "class AnchorUMAP(umap.UMAP):\n",
    "    def __init__(self, include_anchors_in_embedding=False, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Extended UMAP that includes triangle anchors (2-simplices).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        include_anchors_in_embedding : bool, default=True\n",
    "            Whether to include anchor points in the final embedding visualization.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.include_anchors_in_embedding = include_anchors_in_embedding\n",
    "        self.n_anchors_ = 0\n",
    "        self.triangles_ = []\n",
    "        self.metric_kwds = kwargs.get(\"metric_kwds\", {}) or {}\n",
    "\n",
    "    @staticmethod\n",
    "    def find_triangles_from_local(X, knn_indices, min_edge=0.5, tension=2):\n",
    "      \"\"\"\n",
    "      Find triangles and aggregate weights from all three basepoints.\n",
    "      \"\"\"\n",
    "\n",
    "      n_samples, k = knn_indices.shape\n",
    "      triangle_data = defaultdict(list)   # key â†’ list of (w_ab, w_ac, w_bc)\n",
    "\n",
    "      # Precompute stats\n",
    "      local_means = np.zeros(n_samples)\n",
    "      local_stds = np.zeros(n_samples)\n",
    "      local_area_mean = np.zeros(n_samples)\n",
    "\n",
    "      for p in range(n_samples):\n",
    "          neighbors = knn_indices[p]\n",
    "          DM = distance_matrix(X[neighbors], X[neighbors])\n",
    "\n",
    "          local_means[p] = np.mean(DM)\n",
    "          local_stds[p] = np.std(DM)\n",
    "\n",
    "          # baseline triangle area in neighborhood\n",
    "          areas = []\n",
    "          for i in range(k):\n",
    "              for j in range(i+1, k):\n",
    "                  a_idx = neighbors[i]\n",
    "                  b_idx = neighbors[j]\n",
    "                  areas.append(AnchorUMAP.triangle_area(X, p, a_idx, b_idx))\n",
    "\n",
    "          local_area_mean[p] = np.mean(areas) if areas else 1.0\n",
    "\n",
    "\n",
    "      # Search for triangles\n",
    "      for a in range(n_samples):\n",
    "          neighbors = knn_indices[a]\n",
    "\n",
    "          for i in range(k):\n",
    "              for j in range(i+1, k):\n",
    "\n",
    "                  b = neighbors[i]\n",
    "                  c = neighbors[j]\n",
    "\n",
    "                  # mutual neighbor condition\n",
    "                  if (a in knn_indices[b] and c in knn_indices[b] and\n",
    "                      b in knn_indices[c] and a in knn_indices[c]):\n",
    "\n",
    "                      # true distances\n",
    "                      dab = np.linalg.norm(X[b] - X[a])\n",
    "                      dac = np.linalg.norm(X[c] - X[a])\n",
    "                      dbc = np.linalg.norm(X[c] - X[b])\n",
    "\n",
    "                      # z-score these\n",
    "                      mu = (local_means[a] + local_means[b] + local_means[c]) / 3\n",
    "                      sigma = (local_stds[a] + local_stds[b] + local_stds[c]) / 3 + 1e-8\n",
    "\n",
    "                      dab = (dab - mu) / sigma\n",
    "                      dac = (dac - mu) / sigma\n",
    "                      dbc = (dbc - mu) / sigma\n",
    "\n",
    "                      # triangle area\n",
    "                      area = AnchorUMAP.triangle_area(X, a, b, c)\n",
    "                      S = area / (local_area_mean[a] + 1e-8)\n",
    "                      if not (0.05 <= S <= 5.0):\n",
    "                        continue\n",
    "\n",
    "                      # compute weights\n",
    "                      w_ab = AnchorUMAP.weight_fn(dab)\n",
    "                      w_ac = AnchorUMAP.weight_fn(dac)\n",
    "                      w_bc = AnchorUMAP.weight_fn(dbc)\n",
    "\n",
    "                      # canonical ordering of triangle\n",
    "                      key = tuple(sorted((a, b, c)))\n",
    "\n",
    "                      # store contribution (DO NOT FILTER YET)\n",
    "                      triangle_data[key].append((w_ab, w_ac, w_bc))\n",
    "\n",
    "\n",
    "      # Aggregate weights per triangle\n",
    "      triangles = []\n",
    "\n",
    "      for (a, b, c), weights in triangle_data.items():\n",
    "          w_ab = np.mean([w[0] for w in weights])\n",
    "          w_ac = np.mean([w[1] for w in weights])\n",
    "          w_bc = np.mean([w[2] for w in weights])\n",
    "\n",
    "\n",
    "          # simple quality threshold\n",
    "          if np.mean([w_ab, w_ac, w_bc]) > min_edge:\n",
    "              triangles.append((a, b, c,\n",
    "                                tension * w_bc,\n",
    "                                tension * w_ac,\n",
    "                                tension * w_ab))\n",
    "\n",
    "      return triangles\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_fn(d, scale=5.0):\n",
    "      \"\"\"Simple logistic weight on z-scored distances.\"\"\"\n",
    "      return 1 / (1 + np.exp(scale * d))\n",
    "\n",
    "    @staticmethod\n",
    "    def triangle_area(X, a, b, c):\n",
    "        \"\"\"\n",
    "        Computes area of triangle (a,b,c) for points in R^n.\n",
    "        Works for any dimension.\n",
    "        \"\"\"\n",
    "        u = X[b] - X[a]\n",
    "        v = X[c] - X[a]\n",
    "        uu = np.dot(u, u)\n",
    "        vv = np.dot(v, v)\n",
    "        uv = np.dot(u, v)\n",
    "        area_sq = uu * vv - uv * uv\n",
    "        if area_sq <= 0:\n",
    "            return 0.0\n",
    "        return 0.5 * np.sqrt(area_sq)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_area(area, local_mean, eps=1e-8):\n",
    "        return area / (local_mean + eps)\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def make_anchors(triangles, X):\n",
    "        \"\"\"Create anchor points at triangle centroids.\"\"\"\n",
    "        if not triangles:\n",
    "            return np.empty((0, X.shape[1]))\n",
    "\n",
    "        anchor_coords = []\n",
    "        for (a, b, c, w_ab, w_ac, w_bc) in triangles:\n",
    "            #total_w = w_ab + w_ac + w_bc + 1e-9\n",
    "            centroid = (X[a] + X[b] + X[c]) / 3\n",
    "            anchor_coords.append(centroid)\n",
    "        return np.array(anchor_coords)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_anchor_edges(triangles, n_samples):\n",
    "        \"\"\"Build edges connecting anchors to their triangle vertices.\"\"\"\n",
    "        edges = []\n",
    "        for t_id, (a, b, c, w_bc, w_ac, w_ab) in enumerate(triangles):\n",
    "            anchor_idx = n_samples + t_id\n",
    "\n",
    "            # anchor to a (weight comes from edge bc)\n",
    "            edges.append((anchor_idx, a, w_bc))\n",
    "            edges.append((a, anchor_idx, w_bc))\n",
    "\n",
    "            # anchor to b (weight comes from edge ac)\n",
    "            edges.append((anchor_idx, b, w_ac))\n",
    "            edges.append((b, anchor_idx, w_ac))\n",
    "\n",
    "            # anchor to c (weight comes from edge ab)\n",
    "            edges.append((c, anchor_idx, w_ab))\n",
    "            edges.append((anchor_idx, c, w_ab))\n",
    "\n",
    "        return edges\n",
    "\n",
    "    def _build_augmented_graph(self, X, knn_indices, knn_dists, sigmas, rhos, return_dists=None):\n",
    "        \"\"\"Build the fuzzy simplicial set including anchor points.\"\"\"\n",
    "        # Compute standard membership strengths\n",
    "        rows, cols, vals, dists = compute_membership_strengths(\n",
    "            knn_indices, knn_dists, sigmas, rhos, return_dists\n",
    "        )\n",
    "\n",
    "        # Find triangles and create anchors\n",
    "        triangles = self.find_triangles_from_local(X, knn_indices)\n",
    "        self.triangles_ = triangles\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        if len(triangles) > 0:\n",
    "            # Create anchor points\n",
    "            anchors = self.make_anchors(triangles, X)\n",
    "            self.n_anchors_ = anchors.shape[0]\n",
    "\n",
    "            # Augment data with anchors\n",
    "            X_aug = np.vstack([X, anchors])\n",
    "\n",
    "            # Build anchor edges\n",
    "            anchor_edges = self.build_anchor_edges(triangles, n_samples)\n",
    "\n",
    "            # Add anchor edges to graph\n",
    "            if anchor_edges:\n",
    "                anchor_rows, anchor_cols, anchor_vals = zip(*anchor_edges)\n",
    "                rows = np.concatenate([rows, np.array(anchor_rows, dtype=np.int32)])\n",
    "                cols = np.concatenate([cols, np.array(anchor_cols, dtype=np.int32)])\n",
    "                vals = np.concatenate([vals, np.array(anchor_vals, dtype=np.float32)])\n",
    "\n",
    "            # Update graph size to include anchors\n",
    "            graph_size = n_samples + self.n_anchors_\n",
    "        else:\n",
    "            X_aug = X\n",
    "            graph_size = n_samples\n",
    "            self.n_anchors_ = 0\n",
    "\n",
    "        # Create sparse matrix with correct size\n",
    "        graph = sp.coo_matrix(\n",
    "            (vals, (rows, cols)),\n",
    "            shape=(graph_size, graph_size)\n",
    "        )\n",
    "        graph.eliminate_zeros()\n",
    "\n",
    "        return graph, X_aug\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the AnchorUMAP model.\"\"\"\n",
    "        X = X.astype(np.float32)\n",
    "\n",
    "        # Validate random state\n",
    "        if isinstance(self.random_state, (int, np.integer)):\n",
    "            self.random_state = np.random.RandomState(self.random_state)\n",
    "\n",
    "        # Get k-NN graph\n",
    "        knn_indices, knn_dists, _ = nearest_neighbors(\n",
    "            X,\n",
    "            self.n_neighbors,\n",
    "            self.metric,\n",
    "            getattr(self, 'metric_kwds', {}),\n",
    "            getattr(self, 'angular_rp_forest', False),\n",
    "            self.random_state,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "\n",
    "        # Compute membership strengths parameters\n",
    "        sigmas, rhos = smooth_knn_dist(\n",
    "            knn_dists.astype(np.float32),\n",
    "            float(self.n_neighbors),\n",
    "            local_connectivity=float(self.local_connectivity),\n",
    "        )\n",
    "\n",
    "        # Build augmented graph\n",
    "        graph, X_aug = self._build_augmented_graph(\n",
    "            X, knn_indices, knn_dists, sigmas, rhos\n",
    "        )\n",
    "\n",
    "        # Apply set operations\n",
    "        transpose = graph.transpose()\n",
    "        prod_matrix = graph.multiply(transpose)\n",
    "        graph = (\n",
    "            self.set_op_mix_ratio * (graph + transpose - prod_matrix)\n",
    "            + (1.0 - self.set_op_mix_ratio) * prod_matrix\n",
    "        )\n",
    "        graph.eliminate_zeros()\n",
    "\n",
    "        # Compute embedding\n",
    "        self._raw_data = X_aug  # Store augmented data\n",
    "\n",
    "        # Get UMAP parameters\n",
    "        a, b = umap.umap_.find_ab_params(self.spread, self.min_dist)\n",
    "\n",
    "        # Compute embedding for augmented data\n",
    "        embedding = simplicial_set_embedding(\n",
    "            X_aug,\n",
    "            graph,\n",
    "            self.n_components,\n",
    "            self.learning_rate,\n",
    "            a, b,\n",
    "            self.repulsion_strength,\n",
    "            self.negative_sample_rate,\n",
    "            self.n_epochs if self.n_epochs is not None else 200,\n",
    "            init=self.init,\n",
    "            random_state=self.random_state,\n",
    "            metric=self.metric,\n",
    "            metric_kwds=getattr(self, 'metric_kwds', {}),\n",
    "            densmap=False,\n",
    "            densmap_kwds={},\n",
    "            output_dens=False,\n",
    "            verbose=self.verbose,\n",
    "        )[0]\n",
    "\n",
    "        # Store embeddings\n",
    "        if self.include_anchors_in_embedding or self.n_anchors_ == 0:\n",
    "            self.embedding_ = embedding\n",
    "        else:\n",
    "            # Only return original data points in embedding\n",
    "            self.embedding_ = embedding[:X.shape[0]]\n",
    "\n",
    "        # Store anchor embeddings separately\n",
    "        if self.n_anchors_ > 0:\n",
    "            self.anchor_embedding_ = embedding[X.shape[0]:]\n",
    "        else:\n",
    "            self.anchor_embedding_ = np.empty((0, self.n_components))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit the model and return the embedding.\"\"\"\n",
    "        return self.fit(X, y).embedding_\n",
    "\n",
    "    def get_anchor_embeddings(self):\n",
    "        \"\"\"Get the embedding coordinates of anchor points.\"\"\"\n",
    "        if not hasattr(self, 'anchor_embedding_'):\n",
    "            raise ValueError(\"Model must be fitted first\")\n",
    "        return self.anchor_embedding_\n",
    "\n",
    "    def get_triangles(self):\n",
    "        \"\"\"Get the list of triangles used to create anchors.\"\"\"\n",
    "        if not hasattr(self, 'triangles_'):\n",
    "            raise ValueError(\"Model must be fitted first\")\n",
    "        return self.triangles_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXxsnYWY1ALC"
   },
   "source": [
    "# Comparison to regular UMAP\n",
    "We create a function that allows us to compare AnchorUMAP to regular UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLu-EJWiKIl7"
   },
   "outputs": [],
   "source": [
    "def explore_umap_anchor_snapshot(dset, n_neighbors, show_anchors, show_triangles, noise):\n",
    "    # Generate dataset\n",
    "    X, color, is3d = generate_dataset(dset, noise=noise)\n",
    "\n",
    "    # Fit Regular UMAP\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, random_state=42)\n",
    "    umap_emb = umap_model.fit_transform(X)\n",
    "\n",
    "    # Fit AnchorUMAP (no tau)\n",
    "    anchor_model = AnchorUMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        random_state=42,\n",
    "        include_anchors_in_embedding=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    anchor_emb = anchor_model.fit_transform(X)\n",
    "    anchors = anchor_model.get_anchor_embeddings()\n",
    "    triangles = anchor_model.get_triangles()\n",
    "\n",
    "    # Plot\n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # -------------------------------\n",
    "    # Original Data\n",
    "    # -------------------------------\n",
    "    ax1 = fig.add_subplot(131, projection='3d' if is3d else None)\n",
    "    if is3d:\n",
    "        ax1.scatter(X[:,0], X[:,1], X[:,2], c=color, cmap='cividis', s=10)\n",
    "    else:\n",
    "        ax1.scatter(X[:,0], X[:,1], c=color, cmap='cividis', s=10)\n",
    "    ax1.set_title(f\"Original Data: {dset}\", fontsize=12)\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # -------------------------------\n",
    "    # Regular UMAP\n",
    "    # -------------------------------\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax2.scatter(umap_emb[:,0], umap_emb[:,1], c=color, cmap='cividis', s=10)\n",
    "    ax2.set_title(\"Regular UMAP\", fontsize=12)\n",
    "    ax2.axis('equal')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # -------------------------------\n",
    "    # AnchorUMAP\n",
    "    # -------------------------------\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    ax3.scatter(\n",
    "        anchor_emb[:n_samples, 0],\n",
    "        anchor_emb[:n_samples, 1],\n",
    "        c=color,\n",
    "        cmap='cividis',\n",
    "        s=10,\n",
    "        label='Data Points'\n",
    "    )\n",
    "\n",
    "    # Plot triangles\n",
    "    if show_triangles:\n",
    "        for (a, b, c, *_) in triangles:\n",
    "            if a < n_samples and b < n_samples and c < n_samples:\n",
    "                tri_pts = anchor_emb[[a, b, c], :]\n",
    "                poly = Polygon(\n",
    "                    tri_pts,\n",
    "                    closed=True,\n",
    "                    facecolor='red',\n",
    "                    alpha=0.05,\n",
    "                    edgecolor='none'\n",
    "                )\n",
    "                ax3.add_patch(poly)\n",
    "\n",
    "    # Plot anchors\n",
    "    if show_anchors and anchors.shape[0] > 0:\n",
    "        ax3.scatter(\n",
    "            anchors[:,0], anchors[:,1],\n",
    "            c='red', s=40, alpha=0.1,\n",
    "            edgecolors='k', linewidths=0.2,\n",
    "            zorder=3,\n",
    "            label='Anchors'\n",
    "        )\n",
    "\n",
    "    # Title (no tau)\n",
    "    ax3.set_title(\n",
    "        f\"AnchorUMAP (n_neighbors={n_neighbors}, noise={noise:.2f})\",\n",
    "        fontsize=12\n",
    "    )\n",
    "\n",
    "    # Triangle count\n",
    "    ax3.text(\n",
    "        0.02, 0.98,\n",
    "        f\"Triangles: {len(triangles)}\",\n",
    "        transform=ax3.transAxes,\n",
    "        fontsize=11,\n",
    "        color='black',\n",
    "        va='top',\n",
    "        ha='left'\n",
    "    )\n",
    "\n",
    "    ax3.axis('equal')\n",
    "    ax3.axis('off')\n",
    "    ax3.legend(loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, triangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-xwWNv9LWtt"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "\n",
    "Below we have a function that generates a variety of dataset we can use to analyze the way both UMAP and AnchorUMAP react.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQNuH4WABp3l"
   },
   "outputs": [],
   "source": [
    "def generate_dataset(name, noise=0.0):\n",
    "    if name == \"Circle\":\n",
    "        n_samples = 800\n",
    "        theta = np.linspace(0, 2 * np.pi, n_samples)\n",
    "        X = np.c_[np.cos(theta), np.sin(theta)] + noise * np.random.randn(n_samples, 2)\n",
    "        color = theta\n",
    "        return X, color, False\n",
    "\n",
    "    elif name == \"Sphere\":\n",
    "        n_samples = 400\n",
    "        # Sample uniformly on sphere surface\n",
    "        phi = np.arccos(1 - 2*np.random.rand(n_samples))  # polar angle\n",
    "        theta = 2 * np.pi * np.random.rand(n_samples)     # azimuthal angle\n",
    "        x = np.sin(phi) * np.cos(theta)\n",
    "        y = np.sin(phi) * np.sin(theta)\n",
    "        z = np.cos(phi)\n",
    "        X = np.vstack([x, y, z]).T + noise*np.random.randn(n_samples, 3)\n",
    "        color = phi\n",
    "        is3d = True\n",
    "        return X, color, is3d\n",
    "\n",
    "    elif name == \"2D Manifold\":\n",
    "        n_samples = 800\n",
    "        side = int(np.sqrt(n_samples))\n",
    "        u = np.linspace(-1,1,side)\n",
    "        v = np.linspace(-1,1,side)\n",
    "        uu, vv = np.meshgrid(u,v)\n",
    "        x = uu.ravel()\n",
    "        y = vv.ravel()\n",
    "        z = (0.3*np.sin(np.pi*uu)*np.cos(np.pi*vv)).ravel()  # flatten\n",
    "        X = np.vstack([x,y,z]).T + noise*np.random.randn(uu.size, 3)\n",
    "        color = x\n",
    "        is3d = True\n",
    "        return X, color, is3d\n",
    "\n",
    "    elif name == \"Guassian\":\n",
    "        X, y = make_blobs(\n",
    "            n_samples=5000,\n",
    "            n_features=2,\n",
    "            centers=5,\n",
    "            cluster_std=2.0,\n",
    "            random_state=42\n",
    "        )\n",
    "        # Add Gaussian noise\n",
    "        X += np.random.normal(0, noise, X.shape)\n",
    "        return X, y, False  # (data, color labels, is3d flag)\n",
    "\n",
    "    elif name == \"Interlocking Circles\":\n",
    "        n_samples = 800\n",
    "        r = 1.0\n",
    "        offset = 1.2\n",
    "        theta = np.linspace(0, 2 * np.pi, n_samples // 2)\n",
    "        circle1 = np.c_[r * np.cos(theta), r * np.sin(theta)]\n",
    "        circle2 = np.c_[r * np.cos(theta) + offset, r * np.sin(theta)]\n",
    "        X = np.vstack([circle1, circle2]) + noise * np.random.randn(n_samples, 2)\n",
    "        color = np.concatenate([np.zeros(n_samples // 2), np.ones(n_samples // 2)])\n",
    "        return X, color, False\n",
    "\n",
    "    elif name == \"S-Curve\":\n",
    "        X, color = make_s_curve(800, noise=noise)\n",
    "        return X, color, True\n",
    "\n",
    "    elif name == \"Swiss Roll\":\n",
    "        X, color = make_swiss_roll(800, noise=noise)\n",
    "        return X, color, True\n",
    "\n",
    "    elif name == \"Torus\":\n",
    "        n = 30\n",
    "        theta = np.linspace(0, 2 * np.pi, n)\n",
    "        phi = np.linspace(0, 2 * np.pi, n)\n",
    "        theta, phi = np.meshgrid(theta, phi)\n",
    "        R, r = 1.0, 0.4\n",
    "        X = np.stack(\n",
    "            [(R + r * np.cos(phi)) * np.cos(theta),\n",
    "             (R + r * np.cos(phi)) * np.sin(theta),\n",
    "             r * np.sin(phi)], axis=-1\n",
    "        ).reshape(-1, 3)\n",
    "        X += noise * np.random.randn(*X.shape)\n",
    "        color = theta.flatten()\n",
    "        return X, color, True\n",
    "\n",
    "    elif name == \"mnist\":\n",
    "        (x, y), _ = mnist.load_data()\n",
    "        X = x.reshape(len(x), -1) / 255.0\n",
    "        return X[:5000], y[:5000], False\n",
    "\n",
    "    elif name.lower() == \"pbmc3k\":\n",
    "        print(\"Loading PBMC3k and applying PCA preprocessing...\")\n",
    "\n",
    "        adata = sc.datasets.pbmc3k()\n",
    "\n",
    "        sc.pp.filter_genes(adata, min_cells=10)\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "        sc.pp.highly_variable_genes(adata, n_top_genes=2000)\n",
    "        adata = adata[:, adata.var[\"highly_variable\"]]\n",
    "\n",
    "        sc.pp.scale(adata, max_value=10)\n",
    "        sc.tl.pca(adata, svd_solver=\"arpack\", n_comps=50)\n",
    "\n",
    "        X_pca = adata.obsm[\"X_pca\"].astype(np.float32)\n",
    "\n",
    "        # optional labeling\n",
    "        sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)\n",
    "        sc.tl.louvain(adata, resolution=0.8)\n",
    "        labels = adata.obs[\"louvain\"].astype(int)\n",
    "\n",
    "        return X_pca, labels, False\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeixwesSJ0Ep"
   },
   "source": [
    "# Widget Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNfHmSqBD86V"
   },
   "outputs": [],
   "source": [
    "def reset_widgets(widgets_dict):\n",
    "    for w, val in widgets_dict.items():\n",
    "        w.value = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17iorIkvKDbI"
   },
   "outputs": [],
   "source": [
    "def update_plot(dset, n_neighbors, show_anchors, show_triangles, noise):\n",
    "    fig, triangles = explore_umap_anchor_snapshot(\n",
    "        dset, n_neighbors, show_anchors, show_triangles, noise\n",
    "    )\n",
    "    fig_container['fig'] = fig\n",
    "\n",
    "    # Update the triangle count widget\n",
    "    triangle_count_label.value = f\"<b>Triangles found:</b> {len(triangles)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4YDCsKkKSK8"
   },
   "outputs": [],
   "source": [
    "def on_reset_clicked(b):\n",
    "    reset_widgets({\n",
    "        dset_widget: \"Interlocking Circles\",\n",
    "        n_neighbors_widget: 10,\n",
    "        noise_widget: 0.0,\n",
    "        show_anchors_widget: True,\n",
    "        show_triangles_widget: True\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407,
     "referenced_widgets": [
      "c6f656e5754c4a448fa9e10a928ca03d",
      "eea36b510ce942a5889f0d5d55318776",
      "087b0efb8a27466fb6aa52f6778c0150",
      "aed5f4c869224c2d9a0c7cd6f4e5a7de",
      "c38026c41dde4fe9ac52bfe54125913a",
      "3f6dbc10848a429dae3a7027ed9d2aa6",
      "476b90c211b54e46aecdfaad07a3002e",
      "85625a30587c4f97be7914d6316a93e1",
      "0a00c7b712874b549b52bd0169dd9f20",
      "a9260a562eb346628c80cde64750e004",
      "2eb2201f8f3d463196e035de74ae9862",
      "da49ae6c7b914081acf2048656a53d1f",
      "45af7a66adfd44a7a92ab910f5a51397",
      "1a23ba7fb1964b3093f8b4a6ee5f6d39",
      "d5377ab8a19c4ce68075053156144662",
      "cdc59f2e225744e386273e2301fa46bf",
      "09ec5cdd1ada4a309e831734aa217d47",
      "9d51f5786c87487db3873dad04c2ae71",
      "155f0919ca254bf28c88adcee8ea1f63",
      "a0327a738f384eb4bf618c25e66c306a",
      "a555657adefb464cb53767927138993a",
      "dac9a23eee8c4fe7b5b0f7b880057a26",
      "cb1930ca19804d38b9f9d65f1f95ef3f",
      "b4d1ce65dbe44e52ac34f7b22d1bf204",
      "d259fa516edb4c6badbf521e5aaa005b",
      "d55affc5d88245bd831a30e538ec2629",
      "3d8102efda3b44b785532af5f636cb16",
      "c23acbb7a7e54d9e815211371eb2922f",
      "769f8c503a57426a9ec6f47696534968",
      "d5888fb02cb8416aac631ad26b31349d",
      "04bc57568e3e4cce8cb4724c916cc283",
      "d0e36069aaf544c28b3f80c3d0f72e57",
      "6ee54b869a764f729a0c14d44d748e50"
     ]
    },
    "id": "7Bt1iOP5KYdU",
    "outputId": "89e84975-60d3-47db-ef73-a2046f32bb5e"
   },
   "outputs": [],
   "source": [
    "# Layout and styling\n",
    "style = {'description_width': '140px'}\n",
    "layout = Layout(width='400px')\n",
    "\n",
    "# Widgets\n",
    "dset_widget = Dropdown(\n",
    "    options=[\"Circle\", \"Sphere\", \"Gaussian\", \"2D Manifold\", \"Interlocking Circles\",\n",
    "             \"S-Curve\", \"Swiss Roll\", \"Torus\"],\n",
    "    value=\"Interlocking Circles\",\n",
    "    description=\"Dataset:\",\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "n_neighbors_widget = IntSlider(\n",
    "    min=5, max=30, step=1, value=10,\n",
    "    description='n_neighbors:',\n",
    "    continuous_update=False,\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "noise_widget = FloatSlider(\n",
    "    min=0.0, max=0.2, step=0.01, value=0.0,\n",
    "    description='Noise:',\n",
    "    continuous_update=False,\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "show_anchors_widget = Checkbox(\n",
    "    value=False,\n",
    "    description='Show Anchors',\n",
    "    indent=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "show_triangles_widget = Checkbox(\n",
    "    value=True,\n",
    "    description='Show Triangles',\n",
    "    indent=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "triangle_count_label = HTML(\"<b>Triangles found:</b> 0\")\n",
    "\n",
    "# Buttons\n",
    "reset_button = Button(\n",
    "    description='Reset Defaults',\n",
    "    button_style='info',\n",
    "    layout=Layout(width='200px')\n",
    ")\n",
    "\n",
    "# Main control panel\n",
    "controls = VBox([\n",
    "    HTML(\"<b>Model & Data Controls</b>\"),\n",
    "    dset_widget,\n",
    "    n_neighbors_widget,\n",
    "    noise_widget,\n",
    "    HTML(\"<b>Visualization Options</b>\"),\n",
    "    show_anchors_widget,\n",
    "    show_triangles_widget,\n",
    "    triangle_count_label,\n",
    "    HBox(\n",
    "        [reset_button],\n",
    "        layout=Layout(padding='5px 0 0 0', gap='10px')\n",
    "    )\n",
    "], layout=Layout(padding='5px 10px 0px 10px'))\n",
    "\n",
    "# Figure container\n",
    "fig_container = {'fig': None}\n",
    "\n",
    "# Interactive output\n",
    "out = interactive_output(update_plot, {\n",
    "    'dset': dset_widget,\n",
    "    'n_neighbors': n_neighbors_widget,\n",
    "    'noise': noise_widget,\n",
    "    'show_anchors': show_anchors_widget,\n",
    "    'show_triangles': show_triangles_widget\n",
    "})\n",
    "\n",
    "# Reset button callback\n",
    "reset_button.on_click(on_reset_clicked)\n",
    "\n",
    "# Display UI\n",
    "display(\n",
    "    HBox(\n",
    "        [controls, out],\n",
    "        layout=Layout(align_items='flex-start', gap='20px')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpJavpRKD5AE"
   },
   "source": [
    "# Here we begin Quantitative Analysis of datasets that appear in the thesis.\n",
    "\n",
    "I have chosen 3 datasets to focus on.\n",
    "\n",
    "\n",
    "1.   Circle\n",
    "2.   2d-manifold\n",
    "3.   Pbmc3k\n",
    "\n",
    "The 2-d manifold should showcase some effictivenss of the algorithm. The circle should be relatively unnaffected. And we apply anchorUMAP to a realworld dataset to compare with UMAP. When we compare anchorUMAP to UMAP we do not include the anchor points in the final embedding, because we want to compare if we have more accurately captured the geometry or topology of the original dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIoXvelZvfKa"
   },
   "source": [
    "The Wasserstein and Bottleneck distances both quantify how different two persistence diagrams are, so we want smaller numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHkaaNJAFeqN"
   },
   "outputs": [],
   "source": [
    "def quantitative_analysis(dataset_name, n_neighbors=10, noise=0.0,\n",
    "                          subsample=400, maxdim=1, plot=True):\n",
    "    \"\"\"\n",
    "    Quantitatively compare topology preservation of UMAP vs AnchorUMAP.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name : str\n",
    "        One of the names handled by generate_dataset().\n",
    "    n_neighbors : int, default=10\n",
    "        Number of neighbors for both embeddings.\n",
    "    noise : float, default=0.0\n",
    "        Noise level in dataset generation.\n",
    "    subsample : int, default=400\n",
    "        Subsample size for persistence computations.\n",
    "    maxdim : int, default=1\n",
    "        Maximum homology dimension (Hâ‚ = loops; Hâ‚‚ = voids, etc.)\n",
    "    plot : bool, default=True\n",
    "        Whether to show persistence diagrams.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        {\n",
    "            \"dataset\": str,\n",
    "            \"wasserstein_umap\": float,\n",
    "            \"bottleneck_umap\": float,\n",
    "            \"wasserstein_anchor\": float,\n",
    "            \"bottleneck_anchor\": float\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Generate data\n",
    "    X, color, is3d = generate_dataset(dataset_name, noise=noise)\n",
    "    print(f\"Generated dataset: {dataset_name}, shape={X.shape}, is3d={is3d}\")\n",
    "\n",
    "    # Optional subsampling for speed\n",
    "    if len(X) > subsample:\n",
    "        idx = np.random.choice(len(X), subsample, replace=False)\n",
    "        X = X[idx]\n",
    "        color = np.array(color)[idx]\n",
    "\n",
    "    # UMAP embedding\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, random_state=42)\n",
    "    Y_umap = umap_model.fit_transform(X)\n",
    "\n",
    "    # AnchorUMAP embedding\n",
    "    anchor_model = AnchorUMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        random_state=42,\n",
    "        include_anchors_in_embedding=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    Y_anchor = anchor_model.fit_transform(X)\n",
    "\n",
    "    # Compute persistence diagrams\n",
    "    diag_X = ripser(X, maxdim=maxdim)['dgms']\n",
    "    diag_umap = ripser(Y_umap, maxdim=maxdim)['dgms']\n",
    "    diag_anchor = ripser(Y_anchor, maxdim=maxdim)['dgms']\n",
    "\n",
    "    # Compute distances (use Hâ‚ loop features)\n",
    "    w_umap = wasserstein(diag_X[1], diag_umap[1])\n",
    "    b_umap = bottleneck(diag_X[1], diag_umap[1])\n",
    "    w_anchor = wasserstein(diag_X[1], diag_anchor[1])\n",
    "    b_anchor = bottleneck(diag_X[1], diag_anchor[1])\n",
    "\n",
    "    print(f\"=== Quantitative Topological Fidelity: {dataset_name} ===\")\n",
    "    print(f\"UMAP:        Wasserstein={w_umap:.4f}, Bottleneck={b_umap:.4f}\")\n",
    "    print(f\"AnchorUMAP:  Wasserstein={w_anchor:.4f}, Bottleneck={b_anchor:.4f}\")\n",
    "    print(f\"Î”W = {w_umap - w_anchor:+.4f}, Î”B = {b_umap - b_anchor:+.4f}\")\n",
    "\n",
    "    # Plot persistence diagrams\n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        plot_diagrams(diag_X, title=f\"{dataset_name} â€“ Original\", ax=axes[0])\n",
    "        plot_diagrams(diag_umap, title=f\"UMAP\\n(W={w_umap:.3f}, B={b_umap:.3f})\", ax=axes[1])\n",
    "        plot_diagrams(diag_anchor, title=f\"AnchorUMAP\\n(W={w_anchor:.3f}, B={b_anchor:.3f})\", ax=axes[2])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Return results\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"wasserstein_umap\": w_umap,\n",
    "        \"bottleneck_umap\": b_umap,\n",
    "        \"wasserstein_anchor\": w_anchor,\n",
    "        \"bottleneck_anchor\": b_anchor\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lujfmZMuXK7S"
   },
   "source": [
    "Two main topological measuers we use are bottleneck distance and Wasserstein distance. These distances are measures of persistance diagrams. In this case we use Ripser, which creates rips complexes and lets the scale of r approach infinity. Techincally Ripser never computes the whole complex due to efficiency concers, but performs a sufficient caculation to compute presistant cohomology. These measures are connected as if Wasserstein is L-p, then bottleneck is L-inf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGJp1t5-R-hN"
   },
   "source": [
    "Trustworthiness measuers local geometric preservation by observing knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeVZ4jPIR82w"
   },
   "outputs": [],
   "source": [
    "#want close to 1\n",
    "def trustworthiness_analysis(dataset_name, n_neighbors=10, noise=0.0,\n",
    "                             k_local=10, subsample=2000, plot=True):\n",
    "    \"\"\"\n",
    "    Quantitatively compare local neighborhood preservation (trustworthiness)\n",
    "    between UMAP and AnchorUMAP embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name : str\n",
    "        Name of dataset handled by generate_dataset().\n",
    "    n_neighbors : int, default=10\n",
    "        Number of neighbors used in both embeddings.\n",
    "    noise : float, default=0.0\n",
    "        Noise level in dataset generation.\n",
    "    k_local : int, default=10\n",
    "        Neighborhood size for trustworthiness computation.\n",
    "    subsample : int, default=2000\n",
    "        Subsample size for large datasets.\n",
    "    plot : bool, default=True\n",
    "        If True, plot the embeddings and report trustworthiness values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Dictionary with trustworthiness scores for UMAP and AnchorUMAP.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate dataset\n",
    "    X, color, is3d = generate_dataset(dataset_name, noise=noise)\n",
    "    if len(X) > subsample:\n",
    "        idx = np.random.choice(len(X), subsample, replace=False)\n",
    "        X = X[idx]\n",
    "        color = np.array(color)[idx]\n",
    "\n",
    "    print(f\"Dataset: {dataset_name} | Shape={X.shape}\")\n",
    "\n",
    "    # Fit UMAP\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, random_state=42)\n",
    "    Y_umap = umap_model.fit_transform(X)\n",
    "\n",
    "    # Fit AnchorUMAP\n",
    "    anchor_model = AnchorUMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        random_state=42,\n",
    "        include_anchors_in_embedding=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    Y_anchor = anchor_model.fit_transform(X)\n",
    "\n",
    "    # Compute trustworthiness\n",
    "    trust_umap = trustworthiness(X, Y_umap, n_neighbors=k_local)\n",
    "    # Slice Y_anchor to only include the original data points, not the anchors\n",
    "    trust_anchor = trustworthiness(X, Y_anchor[:X.shape[0]], n_neighbors=k_local)\n",
    "\n",
    "    print(f\"=== Local Neighborhood Preservation (k={k_local}) ===\")\n",
    "    print(f\"UMAP:        Trustworthiness = {trust_umap:.4f}\")\n",
    "    print(f\"AnchorUMAP:  Trustworthiness = {trust_anchor:.4f}\")\n",
    "    print(f\"Î” = {trust_anchor - trust_umap:+.4f}\")\n",
    "\n",
    "    # Plot embeddings\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(Y_umap[:, 0], Y_umap[:, 1], c=color, cmap='cividis', s=10)\n",
    "        plt.title(f\"UMAP\\nTrust = {trust_umap:.3f}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        # Plot only the original data points from Y_anchor\n",
    "        plt.scatter(Y_anchor[:X.shape[0], 0], Y_anchor[:X.shape[0], 1], c=color, cmap='cividis', s=10)\n",
    "        plt.title(f\"AnchorUMAP\\nTrust = {trust_anchor:.3f}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Return results\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"trust_umap\": trust_umap,\n",
    "        \"trust_anchor\": trust_anchor,\n",
    "        \"delta_trust\": trust_anchor - trust_umap\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9lY4XkTSEdJ"
   },
   "source": [
    "Spearman's rho measures global structural presrvstion using pairwise distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90wobfJJSsPe"
   },
   "outputs": [],
   "source": [
    "#want close to 1\n",
    "def spearman_rho_analysis(dataset_name, n_neighbors=10, noise=0.0,\n",
    "                          subsample=4000, plot=True):\n",
    "    \"\"\"\n",
    "    Quantitatively compare global distance preservation (Spearman's rho)\n",
    "    between UMAP and AnchorUMAP embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name : str\n",
    "        Name of dataset handled by generate_dataset().\n",
    "    n_neighbors : int, default=10\n",
    "        Number of neighbors used in both embeddings.\n",
    "    noise : float, default=0.0\n",
    "        Noise level in dataset generation.\n",
    "    subsample : int, default=2000\n",
    "        Subsample size for large datasets.\n",
    "    plot : bool, default=True\n",
    "        If True, plot embeddings and print rho values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : dict\n",
    "        Dictionary with Spearman rho correlations for UMAP and AnchorUMAP.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate dataset\n",
    "    X, color, is3d = generate_dataset(dataset_name, noise=noise)\n",
    "    if len(X) > subsample:\n",
    "        idx = np.random.choice(len(X), subsample, replace=False)\n",
    "        X = X[idx]\n",
    "        color = np.array(color)[idx]\n",
    "\n",
    "    print(f\"Dataset: {dataset_name} | Shape={X.shape}\")\n",
    "\n",
    "    # Fit UMAP\n",
    "    umap_model = umap.UMAP(n_neighbors=n_neighbors, random_state=42)\n",
    "    Y_umap = umap_model.fit_transform(X)\n",
    "\n",
    "    # Fit AnchorUMAP\n",
    "    anchor_model = AnchorUMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        random_state=42,\n",
    "        include_anchors_in_embedding=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    Y_anchor = anchor_model.fit_transform(X)\n",
    "\n",
    "    # Compute pairwise distance matrices\n",
    "    D_X = squareform(pdist(X))\n",
    "    D_umap = squareform(pdist(Y_umap))\n",
    "    # Correct: Use only the original data points from Y_anchor for distance computation\n",
    "    D_anchor = squareform(pdist(Y_anchor[:X.shape[0]]))\n",
    "\n",
    "    # Flatten and compute Spearman correlation\n",
    "    rho_umap, _ = spearmanr(D_X.ravel(), D_umap.ravel())\n",
    "    rho_anchor, _ = spearmanr(D_X.ravel(), D_anchor.ravel())\n",
    "\n",
    "    print(\"=== Global Structure Preservation (Spearman's Ï) ===\")\n",
    "    print(f\"UMAP:        Ï = {rho_umap:.4f}\")\n",
    "    print(f\"AnchorUMAP:  Ï = {rho_anchor:.4f}\")\n",
    "    print(f\"Î”Ï = {rho_anchor - rho_umap:+.4f}\")\n",
    "\n",
    "    # Visualization\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(Y_umap[:, 0], Y_umap[:, 1], c=color, cmap='cividis', s=10)\n",
    "        plt.title(f\"UMAP\\nÏ = {rho_umap:.3f}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        # Correct: Plot only the original data points from Y_anchor\n",
    "        plt.scatter(Y_anchor[:X.shape[0], 0], Y_anchor[:X.shape[0], 1], c=color, cmap='cividis', s=10)\n",
    "        plt.title(f\"AnchorUMAP\\nÏ = {rho_anchor:.3f}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"spearman_umap\": rho_umap,\n",
    "        \"spearman_anchor\": rho_anchor,\n",
    "        \"delta_rho\": rho_anchor - rho_umap\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhNBCU1cv2XP"
   },
   "source": [
    "# Quant analysis of the Circle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "NGMQY34vFfea",
    "outputId": "27b41e0f-6001-427a-90b5-1b908049f526"
   },
   "outputs": [],
   "source": [
    "quantitative_analysis(\"Circle\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "l2WJAVFJS06Z",
    "outputId": "1ccbf891-b0a8-4093-e26a-62f39ac42704"
   },
   "outputs": [],
   "source": [
    "trustworthiness_analysis(\"Circle\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "Ns8cLmZ6S5SW",
    "outputId": "d37656da-1e15-4c97-b960-de47f466780e"
   },
   "outputs": [],
   "source": [
    "spearman_rho_analysis(\"Circle\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oder_wLvYHIF"
   },
   "source": [
    "# Quant Annalysis of Swiss Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "6KZ8MPBFYNAu",
    "outputId": "a84bfc10-23ec-4e08-badf-8b3afecac4fe"
   },
   "outputs": [],
   "source": [
    "quantitative_analysis(\"Swiss Roll\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "z6PgTaYeYnCp",
    "outputId": "6344e8c8-754e-4def-fb41-d084de7ef46f"
   },
   "outputs": [],
   "source": [
    "trustworthiness_analysis(\"Swiss Roll\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "_fW-1TXoYrFe",
    "outputId": "f999aefe-a66e-45c0-f222-a9b6dc5a92eb"
   },
   "outputs": [],
   "source": [
    "spearman_rho_analysis(\"Swiss Roll\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQiBpa5BM-sw"
   },
   "source": [
    "# Quant Analysis of 2d-Manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "pJOJeZ8Ip-X1",
    "outputId": "5d3a3fef-a0f9-4c63-ae4e-1dbbcc1f7f42"
   },
   "outputs": [],
   "source": [
    "quantitative_analysis(\"2D Manifold\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "r-aZ2zxOqMC9",
    "outputId": "77560c39-203f-4952-d3d3-70cfc79f1a12"
   },
   "outputs": [],
   "source": [
    "spearman_rho_analysis(\"2D Manifold\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "H9jRmqSNohq-",
    "outputId": "b47e6ae7-faf4-4a2b-96e1-1557b5c46c1f"
   },
   "outputs": [],
   "source": [
    "trustworthiness_analysis(\"2D Manifold\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G4CihVnv_c_"
   },
   "source": [
    " # Quant analysis of Mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "l5wntSSowBve",
    "outputId": "169a063c-8f9d-412b-f180-be2b1805f548"
   },
   "outputs": [],
   "source": [
    "quantitative_analysis(\"mnist\", n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "id": "0RlZdYY3KjsR",
    "outputId": "444faf4c-1cf0-4d81-9c87-a21260cac6f1"
   },
   "outputs": [],
   "source": [
    "trustworthiness_analysis(\"mnist\", n_neighbors=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
